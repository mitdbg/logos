{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset in datasets, get the parsed variables dataframe from ../../datasets/xyz_extended\n",
    "\n",
    "import pandas as pd\n",
    "from dowhy import CausalModel\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "datasets = []\n",
    "directory = \"../../datasets_raw/xyz_extended\"\n",
    "\n",
    "# Get the filenames of all the log files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".log\"):\n",
    "        datasets.append(filename)\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Get the parameters used to generate the log\n",
    "    with open(os.path.join(directory, dataset.split(\".\")[0] + \".json\")) as f:\n",
    "        l = f.readlines()\n",
    "        num_total_variables = int(l[3].split(\":\")[1].strip().strip(\",\"))\n",
    "        noise_radius = int(l[4].split(\":\")[1].strip())\n",
    "\n",
    "    # Get the variable names for x, y, and z\n",
    "    parsed_vars = pd.read_pickle(\n",
    "        \"../../datasets/xyz_extended/\" + dataset + \"_parsed_variables_None_None.pkl\"\n",
    "    )\n",
    "    parsed_vars = parsed_vars.loc[parsed_vars[\"Tag\"].isin([\"x\", \"y\", \"z\"])][\n",
    "        [\"Name\", \"Tag\"]\n",
    "    ]\n",
    "    mapping = {k: v for k, v in zip(parsed_vars[\"Tag\"], parsed_vars[\"Name\"])}\n",
    "\n",
    "    # Read the corresponding columns from the parsed log and reset the column names to x, y, and z\n",
    "    parsed_log = pd.read_pickle(\n",
    "        \"../../datasets/xyz_extended/\" + dataset + \"_parsed_log_None_None.pkl\"\n",
    "    )\n",
    "    data = parsed_log[[\"machine\"] + list(mapping.values())]\n",
    "    data.columns = [\"machine\"] + list(mapping.keys())\n",
    "\n",
    "    # Calculate the max, min and mean for each of xyz for each machine\n",
    "    agg_list = [\"max\", \"min\", \"mean\"]\n",
    "    data = data.groupby(\"machine\").agg(\n",
    "        {\n",
    "            \"x\": agg_list,\n",
    "            \"y\": agg_list,\n",
    "            \"z\": agg_list,\n",
    "        }\n",
    "    )\n",
    "    data.columns = [\"_\".join(col) for col in data.columns]\n",
    "\n",
    "    # For each x-based aggregate, for each y-based aggregate, for each z-based aggregate, calculate the ATE of x on y adjusting for z\n",
    "    effects = {}\n",
    "    for x_agg in agg_list:\n",
    "        for y_agg in agg_list:\n",
    "            for z_agg in agg_list:\n",
    "                print(\"x_agg: \", x_agg, \"y_agg: \", y_agg, \"z_agg: \", z_agg)\n",
    "                # Get the data for this combination of aggregates\n",
    "                data_ = data[\n",
    "                    [\n",
    "                        \"x_\" + x_agg,\n",
    "                        \"y_\" + y_agg,\n",
    "                        \"z_\" + z_agg,\n",
    "                    ]\n",
    "                ]\n",
    "                # Calculate the ATE of x on y adjusting for z using the dowhy package\n",
    "                model = CausalModel(\n",
    "                    data=data_,\n",
    "                    treatment=\"x_\" + x_agg,\n",
    "                    outcome=\"y_\" + y_agg,\n",
    "                    common_causes=[\"z_\" + z_agg],\n",
    "                )\n",
    "                identified_estimand = model.identify_effect(\n",
    "                    proceed_when_unidentifiable=True\n",
    "                )\n",
    "                estimate = model.estimate_effect(\n",
    "                    identified_estimand,\n",
    "                    method_name=\"backdoor.linear_regression\",\n",
    "                    test_significance=False,\n",
    "                )\n",
    "                print(estimate.value)\n",
    "                effects[(x_agg, y_agg, z_agg)] = estimate.value\n",
    "                print(\"------------------\")\n",
    "\n",
    "    effects_df = pd.DataFrame.from_dict(effects, orient=\"index\")\n",
    "    effects_df.columns = [\"ATE\"]\n",
    "    effects_df.reset_index(inplace=True)\n",
    "    effects_df.rename(columns={\"index\": \"Aggregates\"}, inplace=True)\n",
    "    effects_df[\"TrueATE\"] = 2.0\n",
    "    effects_df[\"Error\"] = abs(\n",
    "        (effects_df[\"ATE\"] - effects_df[\"TrueATE\"]) / effects_df[\"TrueATE\"]\n",
    "    )\n",
    "    effects_df.sort_values(by=\"Error\", ascending=True, inplace=True)\n",
    "    effects_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    print(effects_df)\n",
    "\n",
    "    # Find out which aggregates were used in practice\n",
    "    prepared_vars = pd.read_pickle(\n",
    "        \"../../datasets/xyz_extended/\"\n",
    "        + dataset\n",
    "        + \"_prepared_variables_machine_None.pkl\"\n",
    "    )\n",
    "    x_agg = prepared_vars[prepared_vars[\"Base\"] == mapping[\"x\"]][\"Agg\"].values[0]\n",
    "    y_agg = prepared_vars[prepared_vars[\"Base\"] == mapping[\"y\"]][\"Agg\"].values[0]\n",
    "    z_agg = prepared_vars[prepared_vars[\"Base\"] == mapping[\"z\"]][\"Agg\"].values[0]\n",
    "\n",
    "    # Find index of the row in effects_df that corresponds to the aggregates used in practice\n",
    "    idx = effects_df[effects_df[\"Aggregates\"] == (x_agg, y_agg, z_agg)].index[0]\n",
    "\n",
    "    print(\"Dataset: \", dataset)\n",
    "    print(\"Aggregates: \", (x_agg, y_agg, z_agg))\n",
    "    print(\"Index of chosen aggregates: \", idx)\n",
    "    last_idx = len(effects_df) - 1\n",
    "    results[dataset] = (\n",
    "        num_total_variables,\n",
    "        noise_radius,\n",
    "        x_agg,\n",
    "        y_agg,\n",
    "        z_agg,\n",
    "        idx,\n",
    "        effects_df.loc[idx, \"ATE\"],\n",
    "        effects_df.loc[idx, \"Error\"],\n",
    "        effects_df.loc[0, \"Aggregates\"][0],\n",
    "        effects_df.loc[0, \"Aggregates\"][1],\n",
    "        effects_df.loc[0, \"Aggregates\"][2],\n",
    "        effects_df.loc[0, \"ATE\"],\n",
    "        effects_df.loc[0, \"Error\"],\n",
    "        effects_df.loc[last_idx, \"Aggregates\"][0],\n",
    "        effects_df.loc[last_idx, \"Aggregates\"][1],\n",
    "        effects_df.loc[last_idx, \"Aggregates\"][2],\n",
    "        effects_df.loc[last_idx, \"ATE\"],\n",
    "        effects_df.loc[last_idx, \"Error\"],\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "results_df.columns = [\n",
    "    \"V\",\n",
    "    \"R\",\n",
    "    \"x_agg\",\n",
    "    \"y_agg\",\n",
    "    \"z_agg\",\n",
    "    \"idx\",\n",
    "    \"ATE\",\n",
    "    \"Error\",\n",
    "    \"x_agg_best\",\n",
    "    \"y_agg_best\",\n",
    "    \"z_agg_best\",\n",
    "    \"ATE_best\",\n",
    "    \"Error_best\",\n",
    "    \"x_agg_worst\",\n",
    "    \"y_agg_worst\",\n",
    "    \"z_agg_worst\",\n",
    "    \"ATE_worst\",\n",
    "    \"Error_worst\",\n",
    "]\n",
    "results_df[\"Sub-optimality penalty\"] = results_df[\"Error\"] - results_df[\"Error_best\"]\n",
    "results_df[\"Fraction of gap closed\"] =  abs(results_df[\"Error\"] - results_df[\"Error_worst\"])/ abs(results_df[\"Error_best\"] - results_df[\"Error_worst\"])\n",
    "results_df[\"Fraction of gap closed\"] = results_df[\"Fraction of gap closed\"].fillna(1.0)\n",
    "results_df.sort_values(by=['V', 'R'], ascending=[True, True], inplace=True)\n",
    "results_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a horizontal bar chart of the fraction of gap closed, where there is a label of the worst error on the left and a\n",
    "# label of the best error on the right\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a horizontal bar chart of the fraction of gap closed, where there is a label of the worst error on the left and a\n",
    "\n",
    "# label of the best error on the right\n",
    "plt.figure(figsize=(8, 6.5))\n",
    "plt.barh(\n",
    "    np.arange(len(results_df)),\n",
    "    results_df[\"Fraction of gap closed\"],\n",
    "    color=\"#7f9aba\",\n",
    "    height=0.5,\n",
    ")\n",
    "\n",
    "fontsize=18\n",
    "\n",
    "# Add the labels\n",
    "for i in range(len(results_df)):\n",
    "    plt.text(\n",
    "        results_df[\"Fraction of gap closed\"][i]-0.01,\n",
    "        i,\n",
    "        f'{results_df[\"Error\"][i]*100:.2f}% ({results_df[\"Fraction of gap closed\"][i] * 100:.2f} % of gap)',\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        1.01,\n",
    "        i,\n",
    "        f'{results_df[\"Error_best\"][i]*100:.2f}%',\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        -0.01,\n",
    "        i,\n",
    "        f'{results_df[\"Error_worst\"][i]*100:.2f}%',\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        -0.4,\n",
    "        i,\n",
    "        f'R={results_df[\"R\"][i]:.0f}',\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    if i%3 == 0:\n",
    "        plt.text(\n",
    "            -0.44,\n",
    "            i,\n",
    "            f'V={results_df[\"V\"][i]:.0f}',\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            fontsize=fontsize,\n",
    "        )\n",
    "\n",
    "# Hide y ticks\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "\n",
    "# Set x limits from 0 to 1\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "# Flip y axis\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.text(\n",
    "        -0,\n",
    "        -1.2,\n",
    "        f'Worst ATE Error',\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "plt.text(\n",
    "        1,\n",
    "        -1.2,\n",
    "        f'Best ATE Error',\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "# Add x axis label\n",
    "plt.xlabel(\"ATE Error using LOGos-picked Aggregates\", fontsize=fontsize)\n",
    "\n",
    "    \n",
    "plt.show\n",
    "plt.savefig(\"xyz_agg_efficiency.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"Fraction of gap closed\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset in datasets, get the parsed variables dataframe from ../../datasets/xyz_extended\n",
    "\n",
    "import pandas as pd\n",
    "from dowhy import CausalModel\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "datasets = []\n",
    "directory = \"../../datasets_raw/proprietary_logs\"\n",
    "\n",
    "# Get the filenames of all the log files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"normal.log\"):\n",
    "        datasets.append(filename)\n",
    "\n",
    "\n",
    "results_prop = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Get the parameters used to generate the log\n",
    "    with open(os.path.join(directory, dataset.split(\".\")[0] + \".json\")) as f:\n",
    "        l = f.readlines()\n",
    "        faulty_users = int(l[2].split(\":\")[1].strip().strip(\",\"))\n",
    "        fault_prob = int(l[4].strip().strip(','))\n",
    "\n",
    "    # Get the variable names for version and code\n",
    "    mapping = {\"code\":\"73b16c0a_196\", \"version\":\"30731d4c_11\"}\n",
    "\n",
    "    # Read the corresponding columns from the parsed log and reset the column names to x, y, and z\n",
    "    parsed_log = pd.read_pickle(\n",
    "        \"../../datasets/proprietary_logs/proprietary_eval/\" + dataset + \"_parsed_log_None_None.pkl\"\n",
    "    )\n",
    "    data = parsed_log[[\"User\"] + list(mapping.values())]\n",
    "    data.columns = [\"User\"] + list(mapping.keys())\n",
    "\n",
    "\n",
    "    # Calculate the max, min and mean for each of xyz for each machine\n",
    "    agg_list = [\"max\", \"min\", \"mean\"]\n",
    "    data = data.groupby(\"User\").agg(\n",
    "        {\n",
    "            \"code\": agg_list,\n",
    "            \"version\": agg_list,\n",
    "        }\n",
    "    )\n",
    "    data.columns = [\"_\".join(col) for col in data.columns]\n",
    "\n",
    "    # For each x-based aggregate, for each y-based aggregate, for each z-based aggregate, calculate the ATE of x on y adjusting for z\n",
    "    effects = {}\n",
    "    for code_agg in agg_list:\n",
    "        for version_agg in agg_list:\n",
    "            print(\"code_agg: \", code_agg, \"version_agg: \", version_agg)\n",
    "            # Get the data for this combination of aggregates\n",
    "            data_ = data[\n",
    "                [\n",
    "                    \"code_\" + code_agg,\n",
    "                    \"version_\" + version_agg,\n",
    "                ]\n",
    "            ]\n",
    "            # Calculate the ATE of x on y adjusting for z using the dowhy package\n",
    "            model = CausalModel(\n",
    "                data=data_,\n",
    "                treatment=\"version_\" + version_agg,\n",
    "                outcome=\"code_\" + code_agg,\n",
    "            )\n",
    "            identified_estimand = model.identify_effect(\n",
    "                proceed_when_unidentifiable=True\n",
    "            )\n",
    "            estimate = model.estimate_effect(\n",
    "                identified_estimand,\n",
    "                method_name=\"backdoor.linear_regression\",\n",
    "                test_significance=False,\n",
    "            )\n",
    "            print(estimate.value)\n",
    "            effects[(code_agg, version_agg)] = estimate.value\n",
    "            print(\"------------------\")\n",
    "\n",
    "    effects_df = pd.DataFrame.from_dict(effects, orient=\"index\")\n",
    "    effects_df.columns = [\"ATE\"]\n",
    "    effects_df.reset_index(inplace=True)\n",
    "    effects_df.rename(columns={\"index\": \"Aggregates\"}, inplace=True)\n",
    "    effects_df[\"TrueATE\"] = (401*(fault_prob/100.0) + 200*(1-(fault_prob/100.0)) - 401*0.1-200*0.9) / (15.0-14.3)\n",
    "    effects_df[\"Error\"] = abs(\n",
    "        (effects_df[\"ATE\"] - effects_df[\"TrueATE\"]) / effects_df[\"TrueATE\"]\n",
    "    )\n",
    "    effects_df.sort_values(by=\"Error\", ascending=True, inplace=True)\n",
    "    effects_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "    # Find out which aggregates were used in practice\n",
    "    code_agg = 'mean'\n",
    "    version_agg = 'mean'\n",
    "\n",
    "    # Find index of the row in effects_df that corresponds to the aggregates used in practice\n",
    "    idx = effects_df[effects_df[\"Aggregates\"] == (code_agg, version_agg)].index[0]\n",
    "\n",
    "    print(\"Dataset: \", dataset)\n",
    "    print(\"Aggregates: \", (code_agg, version_agg))\n",
    "    print(\"Index of chosen aggregates: \", idx)\n",
    "    last_idx = len(effects_df) - 1\n",
    "    results_prop[dataset] = (\n",
    "        faulty_users/1000,\n",
    "        fault_prob/100.0,\n",
    "        code_agg,\n",
    "        version_agg,\n",
    "        idx,\n",
    "        effects_df.loc[idx, \"ATE\"],\n",
    "        effects_df.loc[idx, \"Error\"],\n",
    "        effects_df.loc[0, \"Aggregates\"][0],\n",
    "        effects_df.loc[0, \"Aggregates\"][1],\n",
    "        effects_df.loc[0, \"ATE\"],\n",
    "        effects_df.loc[0, \"Error\"],\n",
    "        effects_df.loc[last_idx, \"Aggregates\"][0],\n",
    "        effects_df.loc[last_idx, \"Aggregates\"][1],\n",
    "        effects_df.loc[last_idx, \"ATE\"],\n",
    "        effects_df.loc[last_idx, \"Error\"],\n",
    "    )\n",
    "\n",
    "results_df_prop = pd.DataFrame.from_dict(results_prop, orient=\"index\")\n",
    "results_df_prop.columns = [\n",
    "    \"F\",\n",
    "    \"p_f\",\n",
    "    \"code_agg\",\n",
    "    \"version_agg\",\n",
    "    \"idx\",\n",
    "    \"ATE\",\n",
    "    \"Error\",\n",
    "    \"code_agg_best\",\n",
    "    \"version_agg_best\",\n",
    "    \"ATE_best\",\n",
    "    \"Error_best\",\n",
    "    \"code_agg_worst\",\n",
    "    \"version_agg_worst\",\n",
    "    \"ATE_worst\",\n",
    "    \"Error_worst\",\n",
    "]\n",
    "results_df_prop[\"Sub-optimality penalty\"] = results_df_prop[\"Error\"] - results_df_prop[\"Error_best\"]\n",
    "results_df_prop[\"Fraction of gap closed\"] =  abs(results_df_prop[\"Error\"] - results_df_prop[\"Error_worst\"])/ abs(results_df_prop[\"Error_best\"] - results_df_prop[\"Error_worst\"])\n",
    "results_df_prop[\"Fraction of gap closed\"] = results_df_prop[\"Fraction of gap closed\"].fillna(1.0)\n",
    "results_df_prop.sort_values(by=['F', 'p_f'], ascending=[False, False], inplace=True)\n",
    "results_df_prop.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a horizontal bar chart of the fraction of gap closed, where there is a label of the worst error on the left and a\n",
    "# label of the best error on the right\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a horizontal bar chart of the fraction of gap closed, where there is a label of the worst error on the left and a\n",
    "\n",
    "# label of the best error on the right\n",
    "plt.figure(figsize=(8, 6.5))\n",
    "plt.barh(\n",
    "    np.arange(len(results_df_prop)),\n",
    "    results_df_prop[\"Fraction of gap closed\"],\n",
    "    color=\"#7FBA82\",\n",
    "    height=0.5,\n",
    ")\n",
    "\n",
    "fontsize=18\n",
    "\n",
    "# Add the labels\n",
    "for i in range(len(results_df_prop)):\n",
    "    plt.text(\n",
    "        results_df_prop[\"Fraction of gap closed\"][i]-0.01,\n",
    "        i,\n",
    "        f'{results_df_prop[\"Error\"][i]*100:.2f}% ({results_df_prop[\"Fraction of gap closed\"][i] * 100:.2f} % of gap)',\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        1.01,\n",
    "        i,\n",
    "        f'{results_df_prop[\"Error_best\"][i]*100:.2f}%',\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        -0.01,\n",
    "        i,\n",
    "        f'{results_df_prop[\"Error_worst\"][i]*100:.2f}%',\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        -0.4,\n",
    "        i,\n",
    "        f'p_f={results_df_prop[\"p_f\"][i]:.1f}',\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    if i%3 == 0:\n",
    "        plt.text(\n",
    "            -0.44,\n",
    "            i,\n",
    "            f'F={results_df_prop[\"F\"][i]:.2f}',\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            fontsize=fontsize,\n",
    "        )\n",
    "\n",
    "# Hide y ticks\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "\n",
    "# Set x limits from 0 to 1\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "# Flip y axis\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.text(\n",
    "        -0,\n",
    "        -1.2,\n",
    "        f'Worst ATE Error',\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "plt.text(\n",
    "        1,\n",
    "        -1.2,\n",
    "        f'Best ATE Error',\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "# Add x axis label\n",
    "plt.xlabel(\"ATE Error using LOGos-picked Aggregates\", fontsize=fontsize)\n",
    "\n",
    "    \n",
    "plt.show\n",
    "plt.savefig(\"prop_agg_efficiency.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_prop[\"Fraction of gap closed\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results_df_prop[\"Fraction of gap closed\"].mean() + results_df[\"Fraction of gap closed\"].mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logs-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
